{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Size Calculator (WIP)\n",
    "Purpose: we want a version of the [Periscope dashboard](https://app.periscopedata.com/app/adrise:tubi/676521/(Official)-Experimentation-Sample-Size-Calculator), but with additional flexibility of filtering for a specific set of users. \n",
    "\n",
    "The very high level idea of this notebook is:\n",
    "1. Dynamically generate a SQL query based on a set of user-generated inputs. Run the query on Redshift to pull into a dataframe.\n",
    "2. Run through the sample size calculations (with the ability for the user to set parameters). Output a table that displays sample required for all chosen platforms. \n",
    "\n",
    "The bulk of the work is focused on adding flexibility to #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tubi_data_runtime as tdr\n",
    "# import sample_size_calc_utils as sc\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "from statsmodels.stats.power import tt_ind_solve_power\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User filtering\n",
    "The goal of this section is to pull a list of specific users that are eligible for the experiment.\n",
    "- We want this to be dynamic based on the complexity of any filters (see 3 levels below)\n",
    "- We also want this to be interactable, to minimize the amount of adhoc SQL coding\n",
    "\n",
    "#### 3 different levels, in order (lowest to highest) of complexity:\n",
    "1. device_metric_daily\n",
    "    - all_metric_hourly covers the same metrics/attributes available for filtering, although device_metric_daily will be more performant\n",
    "2. all_metric_hourly \n",
    "3. analytics_richevent\n",
    "    - using events level data adds infinite flexibilty, but makes this problem much harder\n",
    "    \n",
    "For our first prototype, let's just use all_metric_hourly to keep it simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class filter_generator(object):\n",
    "    \n",
    "    def attribute_conditions_choices(self):\n",
    "        attribute_conditions = [\n",
    "            '=',\n",
    "            '<>',\n",
    "            'IN',\n",
    "            'IS',\n",
    "            'IS NOT'\n",
    "        ]\n",
    "        return attribute_conditions \n",
    "    \n",
    "    def metric_conditions_choices(self):\n",
    "        metric_conditions =  [\n",
    "            '>',\n",
    "            '<',\n",
    "            '>=',\n",
    "            '<=',\n",
    "            'BETWEEN'\n",
    "        ] + self.attribute_conditions_choices()\n",
    "        return metric_conditions \n",
    "\n",
    "    def filter_attributes_choices(self):\n",
    "        # Possible choices for attribute filtering (from all_metric_hourly): \n",
    "        filter_attributes = [\n",
    "                'no filters',\n",
    "                'user_id',\n",
    "                'device_id',\n",
    "                'platform',\n",
    "                'platform_type',\n",
    "                'country',\n",
    "                'region',\n",
    "                'city',\n",
    "                'dma',\n",
    "                'os',\n",
    "                'os_version',\n",
    "                'manufacturer',\n",
    "                'app_mode',\n",
    "                'app_version',\n",
    "                'device_language',\n",
    "                'content_id',\n",
    "                'program_id',\n",
    "                'content_type',\n",
    "                'tvt_sec' # note: here tvt_sec is treated as an attribute rather than a cumulative metric\n",
    "            ]\n",
    "        return filter_attributes \n",
    "\n",
    "    def filter_metrics_choices(self):\n",
    "    # Possible choices for metric filtering (from all_metric_hourly): \n",
    "        filter_metrics = [\n",
    "            'no filters',\n",
    "            'tvt_sec',\n",
    "            'movie_non_autoplay_tvt_sec',\n",
    "            'series_non_autoplay_tvt_sec',\n",
    "            'autoplay_tvt_sec',\n",
    "            'non_autoplay_tvt_sec',\n",
    "            'series_tvt_sec',\n",
    "            'movie_tvt_sec',\n",
    "            'series_autoplay_tvt_sec',\n",
    "            'movie_autoplay_tvt_sec',\n",
    "            'visit_total_count',\n",
    "            'view_total_count',\n",
    "            'autoplay_view_total_count',\n",
    "            'non_autoplay_view_total_count',\n",
    "            'series_view_total_count',\n",
    "            'movie_view_total_count',\n",
    "            'autoplay_movie_view_total_count',\n",
    "            'autoplay_series_view_total_count',\n",
    "            'complete_5p_total_count',\n",
    "            'complete_30p_total_count',\n",
    "            'complete_70p_total_count',\n",
    "            'complete_90p_total_count',\n",
    "            'episode_complete_30p_total_count',\n",
    "            'episode_complete_70p_total_count',\n",
    "            'episode_complete_90p_total_count',\n",
    "            'movie_complete_30p_total_count',\n",
    "            'movie_complete_70p_total_count',\n",
    "            'movie_complete_90p_total_count',\n",
    "            'ad_impression_total_count',\n",
    "            'ad_break_total_count',\n",
    "            'seek_total_count',\n",
    "            'pause_total_count',\n",
    "            'subtitles_total_count',\n",
    "            'search_total_count',\n",
    "            'user_signup_count',\n",
    "            'device_registration_count',\n",
    "            'signup_or_registration_activity_count',\n",
    "            'cast_count',\n",
    "            'add_to_queue_total_count',\n",
    "            'details_page_visit_total_count',\n",
    "            'onboarding_page_visit_total_count',\n",
    "            'home_page_visit_total_count',\n",
    "            'browse_page_visit_total_count',\n",
    "            'category_page_visit_total_count',\n",
    "            'trailer_start_count',\n",
    "            'unattributed_tvt_sec',\n",
    "            'linear_tvt_sec',\n",
    "            'linear_view_total_count'\n",
    "        ]\n",
    "        return filter_metrics \n",
    "    \n",
    "    def base_amh_query(self):\n",
    "        amh_filter_query = \"\"\"\n",
    "        WITH elig_devices as (\n",
    "            -- Pull list of devices that were active (has any row; don't need TVT >0) in the past 2 weeks\n",
    "            -- Using all_metric_hourly for additional filters\n",
    "            SELECT DISTINCT device_id\n",
    "            FROM tubidw.all_metric_hourly\n",
    "            WHERE DATE_TRUNC('week',hs) >= dateadd('week',-2,DATE_TRUNC('week',GETDATE()))\n",
    "            AND DATE_TRUNC('week',hs) < DATE_TRUNC('week',GETDATE())\n",
    "            {attr_filter} -- attribute filters dynamically populate here\n",
    "\n",
    "        --     for example:\n",
    "        --     AND user_id is not null AND device_id <> user_id   -- Guest vs signed in device\n",
    "        --     AND platform IN ('ROKU', 'AMAZON')                 -- Platform/Platform type specific\n",
    "        --     AND country in ('US')                              -- Geo specific\n",
    "        --     AND os IN ('abcdefg')                              -- OS/version specific\n",
    "        --     AND content_id IN () AND tvt_sec > 0               -- Browsed/watched specific content/content type\n",
    "        --     TODO: currently can't get a metric/attribute combo filter, like \"devices that watched at least 50% of a specific content_id\"\n",
    "        )\n",
    "\n",
    "        -- The next 3 CTEs are a waste of processing if cumul_filter_metric is not used.\n",
    "        -- TODO: Figure out some way to make this dynamic, based on if cumul_filter_metric is used or not\n",
    "        , elig_device_metrics as (\n",
    "            -- For eligible devices, pull their whole history\n",
    "            SELECT DISTINCT\n",
    "                d.device_id,\n",
    "                d.device_first_seen_ts,\n",
    "                d.device_first_view_ts,\n",
    "                d.platform,\n",
    "                d.platform_type,\n",
    "                d.ds,\n",
    "\n",
    "                -- For filtering devices\n",
    "                {cumul_filter_metric} as daily_filter_metric,\n",
    "\n",
    "                -- For calculating metrics\n",
    "                d.tvt_sec,\n",
    "                d.signup_or_registration_activity_count,\n",
    "                d.visit_total_count\n",
    "            FROM tubidw.device_metric_daily as d\n",
    "            JOIN elig_devices as e\n",
    "                ON d.device_id = e.device_id\n",
    "        )\n",
    "\n",
    "        , elig_device_cumul_filter as (\n",
    "            SELECT *, sum(daily_filter_metric) OVER (PARTITION BY device_id, platform_type, platform ORDER BY ds rows between unbounded preceding and current row) as cumul_filter_metric\n",
    "            FROM elig_device_metrics\n",
    "        )\n",
    "\n",
    "        , elig_devices2 as (\n",
    "            SELECT device_id\n",
    "            FROM elig_device_cumul_filter\n",
    "\n",
    "            -- cumulative metric filters dynamically populate below \n",
    "            WHERE 1=1                                  \n",
    "            {metric_filter_where}                      -- for > (greater than) filters, we can use \"where\"\n",
    "            -- AND cumul_filter_metric >= 3600.0       -- example: at least 60 mins of cumulative TVT\n",
    "\n",
    "            GROUP BY 1                                 -- using a group by instead of distinct opens up filtering with \"having\"\n",
    "\n",
    "            HAVING 1=1                                 \n",
    "            {metric_filter_having}                     -- for < (less than) filters, need to use a \"having\" filter with an aggregation on the metric\n",
    "            -- AND max(cumul_filter_metric) <= 3600.0  -- example: less than 60 mins of cumulative TVT\n",
    "        )\n",
    "        \"\"\"\n",
    "        return amh_filter_query\n",
    "    \n",
    "    \n",
    "    def make_sql_where_string(self, field, condition, value):\n",
    "        if field == 'no filters': \n",
    "            return ''\n",
    "        else: \n",
    "            if (condition == '<') | (condition == '<=') | (condition == 'BETWEEN'):\n",
    "            # for < (less than) filters, need to use a \"having\" filter with an aggregation on the metric\n",
    "            # for now, the only aggregation is \"MAX\" but might want to open up to others in the future\n",
    "                return 'AND ' + 'MAX(' + field + ')' + ' ' + condition + ' ' + value + ''\n",
    "            else:\n",
    "                return 'AND ' + field + ' ' + condition + ' ' + value + ''\n",
    "    \n",
    "    \n",
    "    def set_metric_filter_sql_inputs(self, metric_sql):\n",
    "        # initialize sql strings\n",
    "        cumul_metric_str = metric_sql_having = metric_sql_where = ''\n",
    "\n",
    "        if (metric_sql.children[1].value == '<') | (metric_sql.children[1].value == '<=') | (metric_sql.children[1].value == 'BETWEEN'):\n",
    "            cumul_metric_str = metric_sql.children[0].value\n",
    "            metric_sql_having = metric_sql.result\n",
    "        else:\n",
    "            cumul_metric_str = 0\n",
    "            metric_sql_where = metric_sql.result\n",
    "        \n",
    "        return [metric_sql_where, cumul_metric_str, metric_sql_having]\n",
    "\n",
    "    \n",
    "    def generate_filter_cte(self, attribute_sql, metric_sql):\n",
    "#         base_query = getattr(self, 'base_amh_query')()\n",
    "#         base_query_inputs = getattr(self, 'set_metric_filter_sql_inputs')(metric_sql)\n",
    "        base_query = self.base_amh_query()\n",
    "        base_query_inputs = self.set_metric_filter_sql_inputs(metric_sql)\n",
    "        \n",
    "        elig_devices2 = base_query.format(attr_filter = attribute_sql.result,\n",
    "                                          metric_filter_where = base_query_inputs[0],\n",
    "                                          cumul_filter_metric = base_query_inputs[1],\n",
    "                                          metric_filter_having = base_query_inputs[2])\n",
    "        \n",
    "        \n",
    "        return elig_devices2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add in capability to do events level filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw user data CTE\n",
    "Catch-all CTE to pull a list of standard metrics of active devices in the last 4 weeks, from device_metric_daily. \n",
    "- In the future, we may want to improve this to allow flexibility for more complex metrics not available in device_metric_daily \n",
    "- ie. verification rates can only be calculated from analytics_richevent using is_confirmed = 't'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class raw_user_data(object):\n",
    "\n",
    "    def generate_raw_user_data_cte(self):\n",
    "        return \"\"\"\n",
    "            , raw_user_data AS (\n",
    "              SELECT DISTINCT\n",
    "                     a.device_id,\n",
    "                     device_first_seen_ts,\n",
    "                     ds,\n",
    "                     platform_type,\n",
    "                     platform,\n",
    "                     GETDATE() AS last_exposure_ds,\n",
    "                     DATEADD('week', -2, DATE_TRUNC('week', last_exposure_ds)) AS first_exposure_ds,\n",
    "                     -- Metrics\n",
    "                     tvt_sec,\n",
    "                     signup_or_registration_activity_count,\n",
    "                     visit_total_count\n",
    "              FROM elig_device_metrics as a\n",
    "              JOIN elig_devices2 as e    -- TODO: make this dynamic, based on if cumul_filter_metric is used or not\n",
    "                ON a.device_id = e.device_id  \n",
    "              WHERE DATE_TRUNC('week',ds) >= dateadd('week', -4, DATE_TRUNC('week',GETDATE()))\n",
    "                AND DATE_TRUNC('week',ds) < DATE_TRUNC('week', GETDATE())\n",
    "            )\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User data CTE\n",
    "Dynamic CTE that calculates a specific user-chosen metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class metric_switcher(object):\n",
    "    \n",
    "    def generate_user_data_cte(self, metric): # <-- whatever you input here in \"metric\" will choose one of the CTEs below      \n",
    "        # Get the method from 'self'. Default to a lambda.\n",
    "        method = getattr(self, metric, lambda: \"Invalid metric\")\n",
    "        # Call the method as we return it\n",
    "        return method()\n",
    "    \n",
    "    def possible_metrics(self):\n",
    "        # Possible metrics to use for MDE (same as current calculator)\n",
    "        # may want to make this consistent with the primary metrics available in exp dash in the future\n",
    "        metrics = [\n",
    "            'all_tvt_hours',\n",
    "            'capped_tvt',\n",
    "            'new_viewer_first_day_capped_tvt',\n",
    "            'registrations',\n",
    "            'visits',\n",
    "            'viewer_conversion',\n",
    "            'new_viewer_first_day_conversion',\n",
    "            'new_user_1_to_8_days_retained',\n",
    "            'all_user_retained_in_experiment_timeframe',\n",
    "            'ad_impressions'\n",
    "        ]\n",
    "        return metrics\n",
    "        \n",
    "    def choose_metric(self, metric):\n",
    "        return metric\n",
    "\n",
    "    def all_tvt_hours(self):\n",
    "        return \"\"\"\n",
    "        , user_data AS (\n",
    "          SELECT \n",
    "            device_id, ds, platform_type, platform, device_first_seen_ts, first_exposure_ds, \n",
    "            'all_tvt_hours'::text AS metric_name,\n",
    "            'SUM'::text AS metric_collection_method, \n",
    "            tvt_sec / 3600.0 AS metric_value\n",
    "          FROM raw_user_data\n",
    "        )\n",
    "        \"\"\"\n",
    "\n",
    "    def capped_tvt(self):\n",
    "        return \"\"\"\n",
    "        , user_data AS (\n",
    "          SELECT \n",
    "            device_id, ds, platform_type, platform, device_first_seen_ts, first_exposure_ds, \n",
    "            'capped_tvt'::text AS metric_name,\n",
    "            'SUM'::text AS metric_collection_method, \n",
    "            LEAST(tvt_sec / 3600.0, 4.0) AS metric_value \n",
    "          FROM raw_user_data\n",
    "        )\n",
    "        \"\"\"\n",
    "\n",
    "    def new_viewer_first_day_capped_tvt(self):\n",
    "        return \"\"\"\n",
    "        , user_data AS (\n",
    "          SELECT \n",
    "            device_id, ds, platform_type, platform, device_first_seen_ts, first_exposure_ds, \n",
    "            'new_viewer_first_day_capped_tvt'::text AS metric_name,\n",
    "            'SUM'::text AS metric_collection_method, \n",
    "            LEAST(tvt_sec / 3600.0, 4.0) AS metric_value \n",
    "          FROM raw_user_data\n",
    "          WHERE ds >= DATE_TRUNC('day', device_first_seen_ts) AND ds < device_first_seen_ts + INTERVAL '1 day'\n",
    "        )\n",
    "        \"\"\"\n",
    "\n",
    "    def registrations(self):\n",
    "        return \"\"\"\n",
    "        , user_data AS (\n",
    "          SELECT \n",
    "            device_id, ds, platform_type, platform, device_first_seen_ts, first_exposure_ds, \n",
    "            'registrations'::text AS metric_name,\n",
    "            'SUM'::text AS metric_collection_method, \n",
    "            signup_or_registration_activity_count AS metric_value\n",
    "          FROM raw_user_data\n",
    "        )\n",
    "        \"\"\"\n",
    "\n",
    "    def visits(self):\n",
    "        return \"\"\"\n",
    "        , user_data AS (\n",
    "          SELECT \n",
    "            device_id, ds, platform_type, platform, device_first_seen_ts, first_exposure_ds, \n",
    "            'visits'::text AS metric_name,\n",
    "            'SUM'::text AS metric_collection_method, \n",
    "            visit_total_count AS metric_value \n",
    "          FROM raw_user_data\n",
    "        )\n",
    "        \"\"\"\n",
    "\n",
    "    def viewer_conversion(self):\n",
    "        return \"\"\"\n",
    "        , user_data AS (\n",
    "          SELECT \n",
    "            device_id, ds, platform_type, platform, device_first_seen_ts, first_exposure_ds, \n",
    "            'viewer_conversion'::text AS metric_name,\n",
    "            'MAX'::text AS metric_collection_method, \n",
    "            CASE WHEN tvt_sec > 10 THEN 1.0 ELSE 0.0 END AS metric_value \n",
    "          FROM raw_user_data\n",
    "        )\n",
    "        \"\"\"\n",
    "\n",
    "    def new_viewer_first_day_conversion(self):\n",
    "        return \"\"\"\n",
    "        , user_data AS (\n",
    "          SELECT \n",
    "            device_id, ds, platform_type, platform, device_first_seen_ts, first_exposure_ds, \n",
    "            'new_viewer_first_day_conversion'::text AS metric_name,\n",
    "            'MAX'::text AS metric_collection_method, \n",
    "            CASE WHEN tvt_sec > 10 THEN 1.0 ELSE 0.0 END AS metric_value\n",
    "          FROM raw_user_data\n",
    "          WHERE ds >= DATE_TRUNC('day', device_first_seen_ts) AND ds < device_first_seen_ts + INTERVAL '1 day'\n",
    "        )\n",
    "        \"\"\"\n",
    "\n",
    "    def new_user_1_to_8_days_retained(self):\n",
    "        return \"\"\"\n",
    "        , user_data AS (\n",
    "          SELECT \n",
    "            device_id, ds, platform_type, platform, device_first_seen_ts, first_exposure_ds, \n",
    "            'new_user_1_to_8_days_retained'::text AS metric_name,\n",
    "            'MAX'::text AS metric_collection_method, \n",
    "            CASE WHEN ds > device_first_seen_ts + INTERVAL '1 day' AND tvt_sec > 10 THEN 1.0 ELSE 0.0 END AS metric_value \n",
    "          FROM raw_user_data\n",
    "          WHERE ds >= DATE_TRUNC('day', device_first_seen_ts) AND ds < device_first_seen_ts + INTERVAL '8 day'\n",
    "        )\n",
    "        \"\"\"\n",
    "\n",
    "    def all_user_retained_in_experiment_timeframe(self):\n",
    "        return \"\"\"\n",
    "        , user_data AS (\n",
    "          SELECT DISTINCT \n",
    "            device_id, ds, platform_type, platform, device_first_seen_ts, first_exposure_ds, \n",
    "            'all_user_retained_in_experiment_timeframe'::text AS metric_name,\n",
    "            'SUMGREATERTHAN'::text AS metric_collection_method,\n",
    "            1.0 AS metric_value\n",
    "          FROM raw_user_data\n",
    "          WHERE tvt_sec > 10\n",
    "        )\n",
    "        \"\"\"\n",
    "\n",
    "    def ad_impressions(self):\n",
    "        return \"\"\"\n",
    "        , ad_impressions_data AS (\n",
    "            SELECT ds,\n",
    "                   device_id,\n",
    "                   device_first_seen_ts,\n",
    "                   {{ platform_type('platform') }} AS platform_type,\n",
    "                   platform,\n",
    "                   GETDATE() AS last_exposure_ds,\n",
    "                   DATEADD('week', -2, DATE_TRUNC('week', last_exposure_ds)) AS first_exposure_ds,\n",
    "                   COALESCE(ad_impression_total_count, 0)::float AS ad_impression_total_count,\n",
    "                   COALESCE(gross_revenue, 0)::float AS gross_revenue\n",
    "            FROM tubidw.revenue_bydevice_daily\n",
    "            WHERE DATE_TRUNC('week',ds) >= dateadd('week', -4, DATE_TRUNC('week',GETDATE()))\n",
    "              AND DATE_TRUNC('week',ds) < DATE_TRUNC('week', GETDATE())\n",
    "        )\n",
    "\n",
    "        , device_data_impressions AS (\n",
    "            SELECT d.device_id,\n",
    "                   d.ds,\n",
    "                   d.platform_type,\n",
    "                   d.platform,\n",
    "                   d.device_first_seen_ts,\n",
    "                   d.first_exposure_ds,\n",
    "                   SUM(COALESCE(rev.ad_impression_total_count, 0))::float AS ad_impression_total_count,\n",
    "                   SUM(COALESCE(rev.gross_revenue, 0))::float AS gross_revenue\n",
    "            FROM ad_impressions_data AS rev\n",
    "              RIGHT JOIN raw_user_data AS d\n",
    "                ON d.device_id = rev.device_id\n",
    "                AND d.ds = rev.ds\n",
    "            GROUP BY 1, 2, 3, 4, 5, 6\n",
    "        )\n",
    "\n",
    "          -- Impressions\n",
    "        , user_data AS (\n",
    "          SELECT \n",
    "            device_id, ds, platform_type, platform, device_first_seen_ts, first_exposure_ds, \n",
    "            'ad_impressions' AS metric_name,\n",
    "            'SUM' AS metric_collection_method,\n",
    "            ad_impression_total_count AS metric_value\n",
    "          FROM device_data_impressions\n",
    "        )\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric Summary CTE\n",
    "Catch-all code that allows us to summarize/prep the data for CUPED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class metric_summary_cte(object):\n",
    "\n",
    "    def generate_metric_summary_cte(self):\n",
    "        return \"\"\"\n",
    "            , metrics AS (\n",
    "              SELECT DISTINCT\n",
    "                     user_data.device_id,\n",
    "                     platform_type,\n",
    "                     platform,\n",
    "                     metric_name,\n",
    "                     CASE\n",
    "                       WHEN metric_collection_method = 'SUM' THEN SUM(CASE WHEN user_data.ds >= user_data.first_exposure_ds THEN metric_value ELSE 0 END) OVER\n",
    "                        (PARTITION BY user_data.device_id, metric_name)\n",
    "                       WHEN metric_collection_method = 'MAX' THEN MAX(CASE WHEN user_data.ds >= user_data.first_exposure_ds THEN metric_value ELSE 0 END) OVER\n",
    "                        (PARTITION BY user_data.device_id, metric_name)\n",
    "                      WHEN metric_collection_method = 'AVG' THEN AVG(CASE WHEN user_data.ds >= user_data.first_exposure_ds THEN metric_value ELSE NULL END) OVER\n",
    "                        (PARTITION BY user_data.device_id, metric_name)\n",
    "                      WHEN metric_collection_method = 'SUMGREATERTHAN' THEN CASE WHEN (SUM(CASE WHEN user_data.ds >= user_data.first_exposure_ds THEN metric_value ELSE 0 END) OVER\n",
    "                        (PARTITION BY user_data.device_id, metric_name)) > 1 THEN 1.0 ELSE 0.0 END\n",
    "                      ELSE 0 END\n",
    "                     AS metric_result,\n",
    "                    CASE\n",
    "                          WHEN metric_collection_method = 'SUM' THEN\n",
    "                              SUM(CASE WHEN user_data.ds < user_data.first_exposure_ds THEN metric_value ELSE\n",
    "                          (CASE WHEN device_first_seen_ts < user_data.first_exposure_ds - interval '14 day' THEN 0 ELSE NULL END) END) OVER\n",
    "                          (PARTITION BY user_data.device_id, metric_name)\n",
    "                          WHEN metric_collection_method = 'MAX' THEN\n",
    "                              MAX(CASE WHEN user_data.ds < user_data.first_exposure_ds THEN metric_value ELSE\n",
    "                          (CASE WHEN device_first_seen_ts < user_data.first_exposure_ds - interval '14 day' THEN 0 ELSE NULL END) END) OVER\n",
    "                          (PARTITION BY user_data.device_id, metric_name)\n",
    "                          WHEN metric_collection_method = 'AVG' THEN\n",
    "                              AVG(CASE WHEN user_data.ds < user_data.first_exposure_ds THEN metric_value ELSE\n",
    "                          (CASE WHEN device_first_seen_ts < user_data.first_exposure_ds - interval '14 day' THEN 0 ELSE NULL END) END) OVER\n",
    "                          (PARTITION BY user_data.device_id, metric_name)\n",
    "                    WHEN metric_collection_method = 'SUMGREATERTHAN' THEN\n",
    "                      CASE WHEN (SUM(CASE WHEN user_data.ds < user_data.first_exposure_ds THEN metric_value ELSE\n",
    "                          (CASE WHEN device_first_seen_ts < user_data.first_exposure_ds - interval '14 day' THEN 0 ELSE NULL END) END) OVER\n",
    "                          (PARTITION BY user_data.device_id, metric_name)\n",
    "                          ) > 1 THEN 1 ELSE 0 END\n",
    "                          ELSE 0 END AS metric_covariate\n",
    "              FROM user_data\n",
    "            )\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUPED CTEs\n",
    "Catch-all CTE to calculate CUPED for all platforms, platform types, and all Tubi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cuped_cte(object):\n",
    "\n",
    "    def generate_cuped_cte(self):\n",
    "        return \"\"\"\n",
    "            -- Cuped values\n",
    "            , cuped_values_1 AS (\n",
    "              SELECT\n",
    "                *,\n",
    "                AVG(metric_covariate) OVER (PARTITION BY metric_name, platform_type) AS before_covariate_average,\n",
    "                AVG(metric_result) OVER (PARTITION BY metric_name, platform_type) AS after_covariate_average,\n",
    "                STDDEV(metric_covariate) OVER (PARTITION BY metric_name, platform_type) AS covariate_standard_dev,\n",
    "                AVG(metric_covariate) OVER (PARTITION BY metric_name) AS before_covariate_average_total,\n",
    "                AVG(metric_result) OVER (PARTITION BY metric_name) AS after_covariate_average_total,\n",
    "                STDDEV(metric_result) OVER (PARTITION BY metric_name) AS covariate_standard_dev_total\n",
    "              FROM metrics\n",
    "            )\n",
    "\n",
    "            , cuped_values_2 AS (\n",
    "              SELECT\n",
    "                *,\n",
    "                AVG(metric_covariate) OVER (PARTITION BY metric_name, platform) AS before_covariate_average,\n",
    "                AVG(metric_result) OVER (PARTITION BY metric_name, platform) AS after_covariate_average,\n",
    "                STDDEV(metric_covariate) OVER (PARTITION BY metric_name, platform) AS covariate_standard_dev\n",
    "              FROM metrics\n",
    "              WHERE platform in ('ROKU','AMAZON','IPHONE','IPAD','ANDROID','SONY','PS4','COMCAST','VIZIO','XBOXONE','SAMSUNG','COX')\n",
    "            )\n",
    "\n",
    "            , cuped_data_1 AS (\n",
    "              SELECT\n",
    "                metric_name,\n",
    "                AVG(metric_covariate) AS covariate_mean,\n",
    "                1.0 * SUM((metric_covariate - before_covariate_average_total)*(metric_result - after_covariate_average_total)) / NULLIF(STDDEV(metric_covariate)*STDDEV(metric_covariate) * COUNT(*), 0) AS theta\n",
    "              FROM cuped_values_1\n",
    "              GROUP BY 1\n",
    "            )\n",
    "\n",
    "            , cuped_data_2 as (\n",
    "              SELECT\n",
    "                metric_name,\n",
    "                platform_type,\n",
    "                AVG(metric_covariate) AS covariate_mean,\n",
    "                1.0 * SUM((metric_covariate - before_covariate_average)*(metric_result - after_covariate_average)) / NULLIF(STDDEV(metric_covariate)*STDDEV(metric_covariate) * COUNT(*), 0) AS theta\n",
    "              FROM cuped_values_1\n",
    "              WHERE platform_type NOT IN ('WEB')  -- to avoid duplicates with platform\n",
    "              GROUP BY 1, 2\n",
    "            )\n",
    "\n",
    "            , cuped_data_3 as (\n",
    "              SELECT\n",
    "                metric_name,\n",
    "                platform,\n",
    "                AVG(metric_covariate) AS covariate_mean,\n",
    "                1.0 * SUM((metric_covariate - before_covariate_average)*(metric_result - after_covariate_average)) / NULLIF(STDDEV(metric_covariate)*STDDEV(metric_covariate) * COUNT(*), 0) AS theta\n",
    "              FROM cuped_values_2\n",
    "              GROUP BY 1, 2\n",
    "            )\n",
    "\n",
    "            , cuped_metrics_1 as (\n",
    "              SELECT\n",
    "                device_id,\n",
    "                a.metric_name,\n",
    "                metric_result,\n",
    "                metric_covariate,\n",
    "                COALESCE(metric_result - (metric_covariate - covariate_mean) * theta, metric_result) AS cuped_result\n",
    "              FROM cuped_data_1 AS a\n",
    "                INNER JOIN cuped_values_1 b\n",
    "                  ON a.metric_name = b.metric_name\n",
    "            )\n",
    "\n",
    "            , cuped_metrics_2 as (\n",
    "              SELECT\n",
    "                device_id,\n",
    "                a.metric_name,\n",
    "                a.platform_type AS platform,\n",
    "                metric_result,\n",
    "                metric_covariate,\n",
    "                COALESCE(metric_result - (metric_covariate - covariate_mean) * theta, metric_result) AS cuped_result\n",
    "              FROM cuped_data_2 AS a\n",
    "                INNER JOIN cuped_values_1 AS b\n",
    "                  ON a.platform_type = b.platform_type\n",
    "                  AND a.metric_name = b.metric_name\n",
    "            )\n",
    "\n",
    "            , cuped_metrics_3 as (\n",
    "              SELECT\n",
    "                device_id,\n",
    "                a.metric_name,\n",
    "                a.platform,\n",
    "                metric_result,\n",
    "                metric_covariate,\n",
    "                COALESCE(metric_result - (metric_covariate - covariate_mean) * theta, metric_result) AS cuped_result\n",
    "              FROM cuped_data_3 AS a\n",
    "                INNER JOIN cuped_values_2 AS b\n",
    "                  ON a.platform = b.platform\n",
    "                  AND a.metric_name = b.metric_name\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "            , cuped_results AS (\n",
    "                SELECT metric_name,\n",
    "                        'ALL' as platform,\n",
    "                        count(distinct device_id) size,\n",
    "                        avg(metric_result) result_avg,\n",
    "                        STDDEV(metric_result) result_std,\n",
    "                        avg(cuped_result) avg_cuped_result,\n",
    "                        STDDEV(cuped_result) std_cuped_result\n",
    "                FROM cuped_metrics_1\n",
    "                GROUP BY  1, 2\n",
    "\n",
    "                UNION ALL\n",
    "\n",
    "                SELECT metric_name,\n",
    "                       platform,\n",
    "                       COUNT(distinct device_id) size,\n",
    "                       AVG(metric_result) result_avg,\n",
    "                       STDDEV(metric_result) result_std,\n",
    "                       AVG(cuped_result) avg_cuped_result,\n",
    "                       STDDEV(cuped_result) std_cuped_result\n",
    "                FROM cuped_metrics_2\n",
    "                GROUP BY 1, 2\n",
    "\n",
    "                UNION ALL\n",
    "\n",
    "                SELECT metric_name,\n",
    "                       platform,\n",
    "                       COUNT(distinct device_id) size,\n",
    "                       AVG(metric_result) result_avg,\n",
    "                       STDDEV(metric_result) result_std,\n",
    "                       AVG(cuped_result) avg_cuped_result,\n",
    "                       STDDEV(cuped_result) std_cuped_result\n",
    "                FROM cuped_metrics_3\n",
    "                GROUP BY 1, 2\n",
    "            )\n",
    "\n",
    "            SELECT \n",
    "                   metric_name,\n",
    "                   platform,\n",
    "                   size AS observations,\n",
    "                   avg_cuped_result,\n",
    "                   std_cuped_result\n",
    "            FROM cuped_results        \n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glue all CTEs together and query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose attribute filter\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91b1cb65ff4c46e1aede66ab62753f10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='field', options=('no filters', 'user_id', 'device_id', 'platform',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "choose metric filter\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc0926fb23b4a81be3add7d27e5926d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='field', options=('no filters', 'tvt_sec', 'movie_non_autoplay_tvt_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "choose your primary metric\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd54db0e64d1411b95a8531671c10a31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='metric', options=('all_tvt_hours', 'capped_tvt', 'new_viewer_first…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('choose attribute filter')\n",
    "attribute_filter_str = interactive(filter_generator().make_sql_where_string, \n",
    "                                   field = filter_generator().filter_attributes_choices(), \n",
    "                                   condition = filter_generator().attribute_conditions_choices(), \n",
    "                                   value = '')\n",
    "display(attribute_filter_str)\n",
    "\n",
    "print('')\n",
    "print('choose metric filter')\n",
    "metric_filter_str = interactive(filter_generator().make_sql_where_string, \n",
    "                                field = filter_generator().filter_metrics_choices(), \n",
    "                                condition = filter_generator().metric_conditions_choices(), \n",
    "                                value = '')\n",
    "display(metric_filter_str)\n",
    "\n",
    "print('')\n",
    "print('choose your primary metric')\n",
    "metric_str = interactive(metric_switcher().choose_metric, metric = metric_switcher().possible_metrics())\n",
    "display(metric_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "step1 = filter_generator().generate_filter_cte(attribute_sql = attribute_filter_str, metric_sql = metric_filter_str)\n",
    "step2 = raw_user_data().generate_raw_user_data_cte()\n",
    "step3 = metric_switcher().generate_user_data_cte(metric_str.result) \n",
    "step4 = metric_summary_cte().generate_metric_summary_cte() \n",
    "step5 = cuped_ctes().generate_cuped_ctes()\n",
    "\n",
    "FINAL_SQL = step1 + step2 + step3 + step4 + step5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(FINAL_SQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: Exception ignored in: Exception ignored in: Exception ignored in: Exception ignored in: "
     ]
    }
   ],
   "source": [
    "df = tdr.query_redshift(FINAL_SQL).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample size calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative effect size\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73dd7572a6404a98a59d6cc7468bb29c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.01, description='x', max=1.0, step=0.01), Output()), _dom_classes=('…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "number of treatments\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d68a2e8d2ae74d04822ebbe856a208d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='x', max=8), Output()), _dom_classes=('widget-interact',)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "allocation per variation (including control)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd7a341a7d6c45f88922bd1264ac2ff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.5, description='x', max=1.0, step=0.01), Output()), _dom_classes=('w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "power\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95c32a0f46a94599b0fdb36103f9dfd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.8, description='x', max=1.0, step=0.01), Output()), _dom_classes=('w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "alpha\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08051e4ab1be40a1b1dcdcc506b2fd25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.05, description='x', max=1.0, step=0.01), Output()), _dom_classes=('…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def effect(x=0.01):\n",
    "    return x\n",
    "\n",
    "def variations(x=1):\n",
    "    return x\n",
    "\n",
    "def allocation(x=0.50):\n",
    "    return x\n",
    "\n",
    "def power(x=0.8):\n",
    "    return x\n",
    "\n",
    "def alpha(x=0.05):\n",
    "    return x\n",
    "\n",
    "print('relative effect size')\n",
    "EFFECT_SIZE_RELATIVE = interactive(effect, x=(0.0,1.0,0.01))\n",
    "display(EFFECT_SIZE_RELATIVE)\n",
    "\n",
    "print('')\n",
    "print('number of treatments')\n",
    "NUMBER_VARIATIONS = interactive(variations, x=(0,8,1))\n",
    "display(NUMBER_VARIATIONS)\n",
    "\n",
    "print('')\n",
    "print('allocation per variation (including control)')\n",
    "ALLOCATION = interactive(allocation, x=(0.0,1.0,0.01))\n",
    "display(ALLOCATION)\n",
    "\n",
    "print('')\n",
    "print('power')\n",
    "POWER = interactive(power, x=(0.0,1.0,0.01))\n",
    "display(POWER)\n",
    "\n",
    "print('')\n",
    "print('alpha')\n",
    "ALPHA = interactive(alpha, x=(0.0,1.0,0.01))\n",
    "display(ALPHA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Constants ---------- #\n",
    "EFFECT_SIZE_RELATIVE = EFFECT_SIZE_RELATIVE.result\n",
    "NUMBER_VARIATIONS = NUMBER_VARIATIONS.result\n",
    "ALLOCATION = ALLOCATION.result\n",
    "COL_NAME_P = 'avg_cuped_result'\n",
    "STD_COL_NAME = 'std_cuped_result'\n",
    "POWER = POWER.result\n",
    "ALPHA = ALPHA.result\n",
    "RATIO = 1\n",
    "SAMPLING = 1  # TODO: make this dynamic between 1 and 1000 for sampled analytics\n",
    "\n",
    "CORRECTED_ALPHA = ALPHA / NUMBER_VARIATIONS\n",
    "P2_MULTIPLICATIVE_FACTOR =  1 + EFFECT_SIZE_RELATIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.dataresource+json": {
       "data": [
        {
         "avg_cuped_result": 5.13,
         "index": 0,
         "metric_name": "all_tvt_hours",
         "observations": 23619554,
         "platform": "ALL",
         "sample_required": 886759,
         "std_cuped_result": 12.192,
         "weeks_required": 0.2
        },
        {
         "avg_cuped_result": 1.382,
         "index": 1,
         "metric_name": "all_tvt_hours",
         "observations": 2254961,
         "platform": "IPHONE",
         "sample_required": 1438343,
         "std_cuped_result": 4.184,
         "weeks_required": 2.6
        },
        {
         "avg_cuped_result": 8.267,
         "index": 2,
         "metric_name": "all_tvt_hours",
         "observations": 98288,
         "platform": "SONY",
         "sample_required": 692157,
         "std_cuped_result": 17.358,
         "weeks_required": 28.2
        },
        {
         "avg_cuped_result": 7.706,
         "index": 3,
         "metric_name": "all_tvt_hours",
         "observations": 12980460,
         "platform": "OTT",
         "sample_required": 579627,
         "std_cuped_result": 14.808,
         "weeks_required": 0.2
        },
        {
         "avg_cuped_result": 10.08,
         "index": 4,
         "metric_name": "all_tvt_hours",
         "observations": 268144,
         "platform": "XBOXONE",
         "sample_required": 495122,
         "std_cuped_result": 17.902,
         "weeks_required": 7.4
        },
        {
         "avg_cuped_result": 8.094,
         "index": 5,
         "metric_name": "all_tvt_hours",
         "observations": 4795116,
         "platform": "ROKU",
         "sample_required": 445683,
         "std_cuped_result": 13.639,
         "weeks_required": 0.4
        },
        {
         "avg_cuped_result": 6.165,
         "index": 6,
         "metric_name": "all_tvt_hours",
         "observations": 1552611,
         "platform": "COMCAST",
         "sample_required": 409523,
         "std_cuped_result": 9.957,
         "weeks_required": 1.1
        },
        {
         "avg_cuped_result": 6.973,
         "index": 7,
         "metric_name": "all_tvt_hours",
         "observations": 165752,
         "platform": "COX",
         "sample_required": 365449,
         "std_cuped_result": 10.639,
         "weeks_required": 8.8
        },
        {
         "avg_cuped_result": 3.394,
         "index": 8,
         "metric_name": "all_tvt_hours",
         "observations": 746548,
         "platform": "VIZIO",
         "sample_required": 629327,
         "std_cuped_result": 6.797,
         "weeks_required": 3.4
        },
        {
         "avg_cuped_result": 2.332,
         "index": 9,
         "metric_name": "all_tvt_hours",
         "observations": 7295231,
         "platform": "MOBILE",
         "sample_required": 1206511,
         "std_cuped_result": 6.465,
         "weeks_required": 0.7
        },
        {
         "avg_cuped_result": 12.603,
         "index": 10,
         "metric_name": "all_tvt_hours",
         "observations": 2499657,
         "platform": "AMAZON",
         "sample_required": 502777,
         "std_cuped_result": 22.555,
         "weeks_required": 0.8
        },
        {
         "avg_cuped_result": 3.805,
         "index": 11,
         "metric_name": "all_tvt_hours",
         "observations": 1292737,
         "platform": "SAMSUNG",
         "sample_required": 954318,
         "std_cuped_result": 9.381,
         "weeks_required": 3
        },
        {
         "avg_cuped_result": 2.948,
         "index": 12,
         "metric_name": "all_tvt_hours",
         "observations": 362676,
         "platform": "IPAD",
         "sample_required": 847764,
         "std_cuped_result": 6.85,
         "weeks_required": 9.4
        },
        {
         "avg_cuped_result": 2.708,
         "index": 13,
         "metric_name": "all_tvt_hours",
         "observations": 4588485,
         "platform": "ANDROID",
         "sample_required": 1132022,
         "std_cuped_result": 7.272,
         "weeks_required": 1
        },
        {
         "avg_cuped_result": 5.981,
         "index": 14,
         "metric_name": "all_tvt_hours",
         "observations": 352021,
         "platform": "PS4",
         "sample_required": 567326,
         "std_cuped_result": 11.37,
         "weeks_required": 6.4
        }
       ],
       "schema": {
        "fields": [
         {
          "name": "index",
          "type": "integer"
         },
         {
          "name": "metric_name",
          "type": "string"
         },
         {
          "name": "platform",
          "type": "string"
         },
         {
          "name": "observations",
          "type": "integer"
         },
         {
          "name": "avg_cuped_result",
          "type": "number"
         },
         {
          "name": "std_cuped_result",
          "type": "number"
         },
         {
          "name": "sample_required",
          "type": "number"
         },
         {
          "name": "weeks_required",
          "type": "number"
         }
        ],
        "pandas_version": "0.20.0",
        "primaryKey": [
         "index"
        ]
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric_name</th>\n",
       "      <th>platform</th>\n",
       "      <th>observations</th>\n",
       "      <th>avg_cuped_result</th>\n",
       "      <th>std_cuped_result</th>\n",
       "      <th>sample_required</th>\n",
       "      <th>weeks_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all_tvt_hours</td>\n",
       "      <td>ALL</td>\n",
       "      <td>23619554</td>\n",
       "      <td>5.130</td>\n",
       "      <td>12.192</td>\n",
       "      <td>886759.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all_tvt_hours</td>\n",
       "      <td>IPHONE</td>\n",
       "      <td>2254961</td>\n",
       "      <td>1.382</td>\n",
       "      <td>4.184</td>\n",
       "      <td>1438343.0</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all_tvt_hours</td>\n",
       "      <td>SONY</td>\n",
       "      <td>98288</td>\n",
       "      <td>8.267</td>\n",
       "      <td>17.358</td>\n",
       "      <td>692157.0</td>\n",
       "      <td>28.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>all_tvt_hours</td>\n",
       "      <td>OTT</td>\n",
       "      <td>12980460</td>\n",
       "      <td>7.706</td>\n",
       "      <td>14.808</td>\n",
       "      <td>579627.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>all_tvt_hours</td>\n",
       "      <td>XBOXONE</td>\n",
       "      <td>268144</td>\n",
       "      <td>10.080</td>\n",
       "      <td>17.902</td>\n",
       "      <td>495122.0</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>all_tvt_hours</td>\n",
       "      <td>ROKU</td>\n",
       "      <td>4795116</td>\n",
       "      <td>8.094</td>\n",
       "      <td>13.639</td>\n",
       "      <td>445683.0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>all_tvt_hours</td>\n",
       "      <td>COMCAST</td>\n",
       "      <td>1552611</td>\n",
       "      <td>6.165</td>\n",
       "      <td>9.957</td>\n",
       "      <td>409523.0</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>all_tvt_hours</td>\n",
       "      <td>COX</td>\n",
       "      <td>165752</td>\n",
       "      <td>6.973</td>\n",
       "      <td>10.639</td>\n",
       "      <td>365449.0</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>all_tvt_hours</td>\n",
       "      <td>VIZIO</td>\n",
       "      <td>746548</td>\n",
       "      <td>3.394</td>\n",
       "      <td>6.797</td>\n",
       "      <td>629327.0</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>all_tvt_hours</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>7295231</td>\n",
       "      <td>2.332</td>\n",
       "      <td>6.465</td>\n",
       "      <td>1206511.0</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>all_tvt_hours</td>\n",
       "      <td>AMAZON</td>\n",
       "      <td>2499657</td>\n",
       "      <td>12.603</td>\n",
       "      <td>22.555</td>\n",
       "      <td>502777.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>all_tvt_hours</td>\n",
       "      <td>SAMSUNG</td>\n",
       "      <td>1292737</td>\n",
       "      <td>3.805</td>\n",
       "      <td>9.381</td>\n",
       "      <td>954318.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>all_tvt_hours</td>\n",
       "      <td>IPAD</td>\n",
       "      <td>362676</td>\n",
       "      <td>2.948</td>\n",
       "      <td>6.850</td>\n",
       "      <td>847764.0</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>all_tvt_hours</td>\n",
       "      <td>ANDROID</td>\n",
       "      <td>4588485</td>\n",
       "      <td>2.708</td>\n",
       "      <td>7.272</td>\n",
       "      <td>1132022.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>all_tvt_hours</td>\n",
       "      <td>PS4</td>\n",
       "      <td>352021</td>\n",
       "      <td>5.981</td>\n",
       "      <td>11.370</td>\n",
       "      <td>567326.0</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      metric_name platform  observations  avg_cuped_result  std_cuped_result  \\\n",
       "0   all_tvt_hours      ALL      23619554             5.130            12.192   \n",
       "1   all_tvt_hours   IPHONE       2254961             1.382             4.184   \n",
       "2   all_tvt_hours     SONY         98288             8.267            17.358   \n",
       "3   all_tvt_hours      OTT      12980460             7.706            14.808   \n",
       "4   all_tvt_hours  XBOXONE        268144            10.080            17.902   \n",
       "5   all_tvt_hours     ROKU       4795116             8.094            13.639   \n",
       "6   all_tvt_hours  COMCAST       1552611             6.165             9.957   \n",
       "7   all_tvt_hours      COX        165752             6.973            10.639   \n",
       "8   all_tvt_hours    VIZIO        746548             3.394             6.797   \n",
       "9   all_tvt_hours   MOBILE       7295231             2.332             6.465   \n",
       "10  all_tvt_hours   AMAZON       2499657            12.603            22.555   \n",
       "11  all_tvt_hours  SAMSUNG       1292737             3.805             9.381   \n",
       "12  all_tvt_hours     IPAD        362676             2.948             6.850   \n",
       "13  all_tvt_hours  ANDROID       4588485             2.708             7.272   \n",
       "14  all_tvt_hours      PS4        352021             5.981            11.370   \n",
       "\n",
       "    sample_required  weeks_required  \n",
       "0          886759.0             0.2  \n",
       "1         1438343.0             2.6  \n",
       "2          692157.0            28.2  \n",
       "3          579627.0             0.2  \n",
       "4          495122.0             7.4  \n",
       "5          445683.0             0.4  \n",
       "6          409523.0             1.1  \n",
       "7          365449.0             8.8  \n",
       "8          629327.0             3.4  \n",
       "9         1206511.0             0.7  \n",
       "10         502777.0             0.8  \n",
       "11         954318.0             3.0  \n",
       "12         847764.0             9.4  \n",
       "13        1132022.0             1.0  \n",
       "14         567326.0             6.4  "
      ]
     },
     "metadata": {
      "application/vnd.dataresource+json": {}
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------- Functions ---------- #\n",
    "def sample_power_ttest(p1, p2, sd_diff, alpha=0.05, power=0.8, ratio=1):\n",
    "    # Constants\n",
    "    ALTERNATIVE = 'two-sided'\n",
    "\n",
    "    mean_diff = abs(p2 - p1)\n",
    "    std_effect_size = mean_diff / sd_diff\n",
    "    n = tt_ind_solve_power(effect_size=std_effect_size, \n",
    "                         alpha=alpha, \n",
    "                         power=power, \n",
    "                         ratio=ratio, \n",
    "                         alternative=ALTERNATIVE)\n",
    "    return np.array(n).round()    \n",
    "#     return int(round(n))\n",
    "\n",
    "    \n",
    "# ---------- Implementation ---------- #\n",
    "df['sample_required'] =  df.apply(lambda row: sample_power_ttest(\n",
    "    p1 = row[COL_NAME_P],\n",
    "    p2 = row[COL_NAME_P] * P2_MULTIPLICATIVE_FACTOR,\n",
    "    sd_diff = row[STD_COL_NAME],\n",
    "    alpha = CORRECTED_ALPHA,\n",
    "    power = POWER,\n",
    "    ratio = RATIO)\n",
    "                                  , axis=1)\n",
    "\n",
    "df['weeks_required'] = df['sample_required'] / (df['observations'] * 0.5 * ALLOCATION * SAMPLING)\n",
    "\n",
    "df['avg_cuped_result'] = df['avg_cuped_result'].round(3)\n",
    "df['std_cuped_result'] = df['std_cuped_result'].round(3)\n",
    "df['weeks_required'] = df['weeks_required'].round(1)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPENDIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Future improvements: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make the list of available metrics consistent with exp dash\n",
    "# Primary experimentation dash metrics:\n",
    "primary = [\n",
    "    'activations',\n",
    "    'ad_impressions',\n",
    "    'capped_linear_and_vod_tvt_hours_4_hr_per_day',\n",
    "    'capped_tvt_hours_4_hr_per_day',\n",
    "    'linear_and_vod_all_user_retained_in_experiment_timeframe',\n",
    "    'linear_and_vod_viewer_conversion',\n",
    "    'new_user_1_to_8_days_retained',\n",
    "    'new_user_capped_first_day_tvt_hours_4_hr_per_day', \n",
    "    'new_viewer_first_day_conversion',\n",
    "    'signups',\n",
    "    'viewer_5_min_conversion',\n",
    "    'visits'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example events level query\n",
    "# ANALYTICS_FILTER_QUERY \"\"\"\n",
    "#   SELECT\n",
    "#     device_id,\n",
    "#     device_first_seen_ts,\n",
    "#     DATE_TRUNC('day', ts) AS ds,\n",
    "#     DATEADD('week',-2,DATE_TRUNC('week',GETDATE())) as first_exposure_ds,\n",
    "#     platform,\n",
    "#     platform_type,\n",
    "#     max(case when is_confirmed = 't' then 1 else 0 end) AS metric_value\n",
    "#   from\n",
    "#     tubidw.sampled_analytics_thousandth -- sampled table\n",
    "#   where\n",
    "#     DATE_TRUNC('week',ts) >= dateadd('week',-4,DATE_TRUNC('week',GETDATE()))\n",
    "#     and DATE_TRUNC('week',ts) < DATE_TRUNC('week',GETDATE())\n",
    "    \n",
    "#     and user_id != device_id -- signed in condition\n",
    "#     AND UPPER(platform) IN ('WEB', 'IPHONE')\n",
    "#     AND device_first_seen_ts IS NOT NULL\n",
    "#   group by\n",
    "#     1,2,3,4,5,6\n",
    "# \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
