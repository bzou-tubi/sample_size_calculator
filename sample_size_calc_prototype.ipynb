{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Size Calculator (WIP)\n",
    "Purpose: we want a version of the [Periscope dashboard](https://app.periscopedata.com/app/adrise:tubi/676521/(Official)-Experimentation-Sample-Size-Calculator), but with additional flexibility of filtering for a specific set of users. \n",
    "\n",
    "The very high level concept of this tool:\n",
    "1. Dynamically generate a SQL query based on a set of user-generated inputs. Run the query on Redshift to pull into a dataframe.\n",
    "2. Run through the sample size calculations (with the ability for the user to set custom parameters). Output a table that displays sample required for all chosen platforms. \n",
    "\n",
    "The bulk of the work is focused on adding flexibility to #1. This tool is WIP and there are many improvements to be done (in order of priority):\n",
    "- Adding analytics_richevent filtering capabilities (ie. can we pull all users who watched 70% of a video, then hit the back button?)\n",
    "- Adding capability to have more than 1 attribute and metric filter\n",
    "- Adding flexibility for the user to define their own primary metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tubi_data_runtime as tdr\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "from statsmodels.stats.power import tt_ind_solve_power\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from ssc_utils.filter_generator import filter_generator\n",
    "from ssc_utils.raw_user_data import raw_user_data\n",
    "from ssc_utils.metric_switcher import metric_switcher\n",
    "from ssc_utils.metric_summary import metric_summary\n",
    "from ssc_utils.cuped import cuped\n",
    "import ssc_utils.calculator as c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "\n",
    "The general workflow of this tool (for internal; will alter the description of this section to be more user friendly in the future):\n",
    "\n",
    "### 1. User filtering\n",
    "The goal of this section is to pull a list of specific users that are eligible for the experiment. This is where the bulk of our efforts will be focused. \n",
    "- We want this to be dynamic based on the complexity of any filters (see 3 levels below)\n",
    "- We also want this to be interactable, to minimize the amount of adhoc SQL coding. It's daunting (and unscalable) for our stakeholders to alter the SQL in our current calculator to fit their specific needs. \n",
    "\n",
    "##### 3 different levels, in order of complexity (easiest to hardest):\n",
    "1. device_metric_daily\n",
    "    - all_metric_hourly covers the same metrics/attributes available for filtering, although device_metric_daily will be more performant\n",
    "2. all_metric_hourly \n",
    "3. analytics_richevent\n",
    "    - using events level data adds near infinite flexibilty, but makes this problem much harder\n",
    "    \n",
    "For our first prototype, we're only using all_metric_hourly to cover most filtering cases. To achieve a higher level of filtering flexibilty, we will include analytics_richevent. To reduce run times and processing work, we can include device_metric_daily.\n",
    "\n",
    "#### In general, there are 2 ways to filter users:\n",
    "1. Attributes (ie. ROKU+AMAZON, certain os, kids mode only, etc.)\n",
    "2. Metrics (ie. watched at least 60 mins TVT, completed 3 movies, etc.)\n",
    "\n",
    "### 2. Raw user data\n",
    "Catch-all CTE to pull a list of standard metrics of active devices in the last 4 weeks, from device_metric_daily. \n",
    "- In the future, we may want to improve this to allow flexibility for more complex metrics not available in device_metric_daily \n",
    "- ie. verification rates can only be calculated from analytics_richevent using is_confirmed = 't'\n",
    "\n",
    "### 3. User data\n",
    "Dynamic CTE that calculates a specific user-chosen metric.\n",
    "\n",
    "### 4. Metric summary\n",
    "Catch-all CTE that allows us to summarize/prep the data for CUPED.\n",
    "\n",
    "### 5. CUPED\n",
    "Catch-all CTE to calculate CUPED for all platforms, platform types, and all Tubi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive calculator (end user starts here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose attribute filter\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c950b274b041a2bb014ee89d3e2b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='field', options=('no filters', 'user_id', 'device_id', 'platform',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "choose metric filter\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b40fd02c6fe1473e8ba83b97b9f565e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='field', options=('no filters', 'tvt_sec', 'movie_non_autoplay_tvt_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "choose your primary metric\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046e87588c57488180e7e43aae41ac77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='metric', options=('all_tvt_hours', 'capped_tvt', 'new_viewer_first…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('choose attribute filter')\n",
    "attribute_filter_str = interactive(filter_generator().make_sql_where_string, \n",
    "                                   field = filter_generator().filter_attributes_choices(), \n",
    "                                   condition = filter_generator().attribute_conditions_choices(), \n",
    "                                   value = '')\n",
    "display(attribute_filter_str)\n",
    "\n",
    "print('')\n",
    "print('choose metric filter')\n",
    "metric_filter_str = interactive(filter_generator().make_sql_where_string, \n",
    "                                field = filter_generator().filter_metrics_choices(), \n",
    "                                condition = filter_generator().metric_conditions_choices(), \n",
    "                                value = '')\n",
    "display(metric_filter_str)\n",
    "\n",
    "print('')\n",
    "print('choose your primary metric')\n",
    "metric_str = interactive(metric_switcher().choose_metric, metric = metric_switcher().possible_metrics())\n",
    "display(metric_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative effect size\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "802b0093443b4e1cb7c07f3546502807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.01, description='x', max=1.0, step=0.01), Output()), _dom_classes=('…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "number of treatments\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03b883ce4e334bc598fe537a8ec22de8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='x', max=8), Output()), _dom_classes=('widget-interact',)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "allocation per variation (including control)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1227c599508c4441b2a4041ef96c017f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.5, description='x', max=1.0, step=0.01), Output()), _dom_classes=('w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "power\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad994680e23e404bb68968ec029f6ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.8, description='x', max=1.0, step=0.01), Output()), _dom_classes=('w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "alpha\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a8e87daf6244849b9ae3e02f845d88e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.05, description='x', max=1.0, step=0.01), Output()), _dom_classes=('…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('relative effect size')\n",
    "EFFECT_SIZE_RELATIVE = interactive(c.effect, x=(0.0,1.0,0.01))\n",
    "display(EFFECT_SIZE_RELATIVE)\n",
    "\n",
    "print('')\n",
    "print('number of treatments')\n",
    "NUMBER_VARIATIONS = interactive(c.variations, x=(0,8,1))\n",
    "display(NUMBER_VARIATIONS)\n",
    "\n",
    "print('')\n",
    "print('allocation per variation (including control)')\n",
    "ALLOCATION = interactive(c.allocation, x=(0.0,1.0,0.01))\n",
    "display(ALLOCATION)\n",
    "\n",
    "print('')\n",
    "print('power')\n",
    "POWER = interactive(c.power, x=(0.0,1.0,0.01))\n",
    "display(POWER)\n",
    "\n",
    "print('')\n",
    "print('alpha')\n",
    "ALPHA = interactive(c.alpha, x=(0.0,1.0,0.01))\n",
    "display(ALPHA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After the user specifies the settings, run everything below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "step1 = filter_generator().generate_filter_cte(attribute_sql = attribute_filter_str, metric_sql = metric_filter_str)\n",
    "step2 = raw_user_data().generate_raw_user_data_cte()\n",
    "step3 = metric_switcher().generate_user_data_cte(metric_str.result) \n",
    "step4 = metric_summary().generate_metric_summary_cte() \n",
    "step5 = cuped().generate_cuped_cte()\n",
    "\n",
    "FINAL_SQL = step1 + step2 + step3 + step4 + step5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        WITH elig_devices as (\n",
      "            -- Pull list of devices that were active (has any row; don't need TVT >0) in the past 2 weeks\n",
      "            -- Using all_metric_hourly for additional filters\n",
      "            SELECT DISTINCT device_id\n",
      "            FROM tubidw.all_metric_hourly\n",
      "            WHERE DATE_TRUNC('week',hs) >= dateadd('week',-2,DATE_TRUNC('week',GETDATE()))\n",
      "            AND DATE_TRUNC('week',hs) < DATE_TRUNC('week',GETDATE())\n",
      "             -- attribute filters dynamically populate here\n",
      "\n",
      "        --     for example:\n",
      "        --     AND user_id is not null AND device_id <> user_id   -- Guest vs signed in device\n",
      "        --     AND platform IN ('ROKU', 'AMAZON')                 -- Platform/Platform type specific\n",
      "        --     AND country in ('US')                              -- Geo specific\n",
      "        --     AND os IN ('abcdefg')                              -- OS/version specific\n",
      "        --     AND content_id IN () AND tvt_sec > 0               -- Browsed/watched specific content/content type\n",
      "        --     TODO: currently can't get a metric/attribute combo filter, like \"devices that watched at least 50% of a specific content_id\"\n",
      "        )\n",
      "\n",
      "        -- The next 3 CTEs are a waste of processing if cumul_filter_metric is not used.\n",
      "        -- TODO: Figure out some way to make this dynamic, based on if cumul_filter_metric is used or not\n",
      "        , elig_device_metrics as (\n",
      "            -- For eligible devices, pull their whole history\n",
      "            SELECT DISTINCT\n",
      "                d.device_id,\n",
      "                d.device_first_seen_ts,\n",
      "                d.device_first_view_ts,\n",
      "                d.platform,\n",
      "                d.platform_type,\n",
      "                d.ds,\n",
      "\n",
      "                -- For filtering devices\n",
      "                0 as daily_filter_metric,\n",
      "\n",
      "                -- For calculating metrics\n",
      "                d.tvt_sec,\n",
      "                d.signup_or_registration_activity_count,\n",
      "                d.visit_total_count\n",
      "            FROM tubidw.device_metric_daily as d\n",
      "            JOIN elig_devices as e\n",
      "                ON d.device_id = e.device_id\n",
      "        )\n",
      "\n",
      "        , elig_device_cumul_filter as (\n",
      "            SELECT *, sum(daily_filter_metric) OVER (PARTITION BY device_id, platform_type, platform ORDER BY ds rows between unbounded preceding and current row) as cumul_filter_metric\n",
      "            FROM elig_device_metrics\n",
      "        )\n",
      "\n",
      "        , elig_devices2 as (\n",
      "            SELECT device_id\n",
      "            FROM elig_device_cumul_filter\n",
      "\n",
      "            -- cumulative metric filters dynamically populate below \n",
      "            WHERE 1=1                                  \n",
      "                                  -- for > (greater than) filters, we can use \"where\"\n",
      "            -- AND cumul_filter_metric >= 3600.0       -- example: at least 60 mins of cumulative TVT\n",
      "\n",
      "            GROUP BY 1                                 -- using a group by instead of distinct opens up filtering with \"having\"\n",
      "\n",
      "            HAVING 1=1                                 \n",
      "                                 -- for < (less than) filters, need to use a \"having\" filter with an aggregation on the metric\n",
      "            -- AND max(cumul_filter_metric) <= 3600.0  -- example: less than 60 mins of cumulative TVT\n",
      "        )\n",
      "        \n",
      "            , raw_user_data AS (\n",
      "              SELECT DISTINCT\n",
      "                     a.device_id,\n",
      "                     device_first_seen_ts,\n",
      "                     ds,\n",
      "                     platform_type,\n",
      "                     platform,\n",
      "                     GETDATE() AS last_exposure_ds,\n",
      "                     DATEADD('week', -2, DATE_TRUNC('week', last_exposure_ds)) AS first_exposure_ds,\n",
      "                     -- Metrics\n",
      "                     tvt_sec,\n",
      "                     signup_or_registration_activity_count,\n",
      "                     visit_total_count\n",
      "              FROM elig_device_metrics as a\n",
      "              JOIN elig_devices2 as e    -- TODO: make this dynamic, based on if cumul_filter_metric is used or not\n",
      "                ON a.device_id = e.device_id  \n",
      "              WHERE DATE_TRUNC('week',ds) >= dateadd('week', -4, DATE_TRUNC('week',GETDATE()))\n",
      "                AND DATE_TRUNC('week',ds) < DATE_TRUNC('week', GETDATE())\n",
      "            )\n",
      "        \n",
      "        , user_data AS (\n",
      "          SELECT \n",
      "            device_id, ds, platform_type, platform, device_first_seen_ts, first_exposure_ds, \n",
      "            'all_tvt_hours'::text AS metric_name,\n",
      "            'SUM'::text AS metric_collection_method, \n",
      "            tvt_sec / 3600.0 AS metric_value\n",
      "          FROM raw_user_data\n",
      "        )\n",
      "        \n",
      "            , metrics AS (\n",
      "              SELECT DISTINCT\n",
      "                     user_data.device_id,\n",
      "                     platform_type,\n",
      "                     platform,\n",
      "                     metric_name,\n",
      "                     CASE\n",
      "                       WHEN metric_collection_method = 'SUM' THEN SUM(CASE WHEN user_data.ds >= user_data.first_exposure_ds THEN metric_value ELSE 0 END) OVER\n",
      "                        (PARTITION BY user_data.device_id, metric_name)\n",
      "                       WHEN metric_collection_method = 'MAX' THEN MAX(CASE WHEN user_data.ds >= user_data.first_exposure_ds THEN metric_value ELSE 0 END) OVER\n",
      "                        (PARTITION BY user_data.device_id, metric_name)\n",
      "                      WHEN metric_collection_method = 'AVG' THEN AVG(CASE WHEN user_data.ds >= user_data.first_exposure_ds THEN metric_value ELSE NULL END) OVER\n",
      "                        (PARTITION BY user_data.device_id, metric_name)\n",
      "                      WHEN metric_collection_method = 'SUMGREATERTHAN' THEN CASE WHEN (SUM(CASE WHEN user_data.ds >= user_data.first_exposure_ds THEN metric_value ELSE 0 END) OVER\n",
      "                        (PARTITION BY user_data.device_id, metric_name)) > 1 THEN 1.0 ELSE 0.0 END\n",
      "                      ELSE 0 END\n",
      "                     AS metric_result,\n",
      "                    CASE\n",
      "                          WHEN metric_collection_method = 'SUM' THEN\n",
      "                              SUM(CASE WHEN user_data.ds < user_data.first_exposure_ds THEN metric_value ELSE\n",
      "                          (CASE WHEN device_first_seen_ts < user_data.first_exposure_ds - interval '14 day' THEN 0 ELSE NULL END) END) OVER\n",
      "                          (PARTITION BY user_data.device_id, metric_name)\n",
      "                          WHEN metric_collection_method = 'MAX' THEN\n",
      "                              MAX(CASE WHEN user_data.ds < user_data.first_exposure_ds THEN metric_value ELSE\n",
      "                          (CASE WHEN device_first_seen_ts < user_data.first_exposure_ds - interval '14 day' THEN 0 ELSE NULL END) END) OVER\n",
      "                          (PARTITION BY user_data.device_id, metric_name)\n",
      "                          WHEN metric_collection_method = 'AVG' THEN\n",
      "                              AVG(CASE WHEN user_data.ds < user_data.first_exposure_ds THEN metric_value ELSE\n",
      "                          (CASE WHEN device_first_seen_ts < user_data.first_exposure_ds - interval '14 day' THEN 0 ELSE NULL END) END) OVER\n",
      "                          (PARTITION BY user_data.device_id, metric_name)\n",
      "                    WHEN metric_collection_method = 'SUMGREATERTHAN' THEN\n",
      "                      CASE WHEN (SUM(CASE WHEN user_data.ds < user_data.first_exposure_ds THEN metric_value ELSE\n",
      "                          (CASE WHEN device_first_seen_ts < user_data.first_exposure_ds - interval '14 day' THEN 0 ELSE NULL END) END) OVER\n",
      "                          (PARTITION BY user_data.device_id, metric_name)\n",
      "                          ) > 1 THEN 1 ELSE 0 END\n",
      "                          ELSE 0 END AS metric_covariate\n",
      "              FROM user_data\n",
      "            )\n",
      "        \n",
      "            -- Cuped values\n",
      "            , cuped_values_1 AS (\n",
      "              SELECT\n",
      "                *,\n",
      "                AVG(metric_covariate) OVER (PARTITION BY metric_name, platform_type) AS before_covariate_average,\n",
      "                AVG(metric_result) OVER (PARTITION BY metric_name, platform_type) AS after_covariate_average,\n",
      "                STDDEV(metric_covariate) OVER (PARTITION BY metric_name, platform_type) AS covariate_standard_dev,\n",
      "                AVG(metric_covariate) OVER (PARTITION BY metric_name) AS before_covariate_average_total,\n",
      "                AVG(metric_result) OVER (PARTITION BY metric_name) AS after_covariate_average_total,\n",
      "                STDDEV(metric_result) OVER (PARTITION BY metric_name) AS covariate_standard_dev_total\n",
      "              FROM metrics\n",
      "            )\n",
      "\n",
      "            , cuped_values_2 AS (\n",
      "              SELECT\n",
      "                *,\n",
      "                AVG(metric_covariate) OVER (PARTITION BY metric_name, platform) AS before_covariate_average,\n",
      "                AVG(metric_result) OVER (PARTITION BY metric_name, platform) AS after_covariate_average,\n",
      "                STDDEV(metric_covariate) OVER (PARTITION BY metric_name, platform) AS covariate_standard_dev\n",
      "              FROM metrics\n",
      "              WHERE platform in ('ROKU','AMAZON','IPHONE','IPAD','ANDROID','SONY','PS4','COMCAST','VIZIO','XBOXONE','SAMSUNG','COX')\n",
      "            )\n",
      "\n",
      "            , cuped_data_1 AS (\n",
      "              SELECT\n",
      "                metric_name,\n",
      "                AVG(metric_covariate) AS covariate_mean,\n",
      "                1.0 * SUM((metric_covariate - before_covariate_average_total)*(metric_result - after_covariate_average_total)) / NULLIF(STDDEV(metric_covariate)*STDDEV(metric_covariate) * COUNT(*), 0) AS theta\n",
      "              FROM cuped_values_1\n",
      "              GROUP BY 1\n",
      "            )\n",
      "\n",
      "            , cuped_data_2 as (\n",
      "              SELECT\n",
      "                metric_name,\n",
      "                platform_type,\n",
      "                AVG(metric_covariate) AS covariate_mean,\n",
      "                1.0 * SUM((metric_covariate - before_covariate_average)*(metric_result - after_covariate_average)) / NULLIF(STDDEV(metric_covariate)*STDDEV(metric_covariate) * COUNT(*), 0) AS theta\n",
      "              FROM cuped_values_1\n",
      "              WHERE platform_type NOT IN ('WEB')  -- to avoid duplicates with platform\n",
      "              GROUP BY 1, 2\n",
      "            )\n",
      "\n",
      "            , cuped_data_3 as (\n",
      "              SELECT\n",
      "                metric_name,\n",
      "                platform,\n",
      "                AVG(metric_covariate) AS covariate_mean,\n",
      "                1.0 * SUM((metric_covariate - before_covariate_average)*(metric_result - after_covariate_average)) / NULLIF(STDDEV(metric_covariate)*STDDEV(metric_covariate) * COUNT(*), 0) AS theta\n",
      "              FROM cuped_values_2\n",
      "              GROUP BY 1, 2\n",
      "            )\n",
      "\n",
      "            , cuped_metrics_1 as (\n",
      "              SELECT\n",
      "                device_id,\n",
      "                a.metric_name,\n",
      "                metric_result,\n",
      "                metric_covariate,\n",
      "                COALESCE(metric_result - (metric_covariate - covariate_mean) * theta, metric_result) AS cuped_result\n",
      "              FROM cuped_data_1 AS a\n",
      "                INNER JOIN cuped_values_1 b\n",
      "                  ON a.metric_name = b.metric_name\n",
      "            )\n",
      "\n",
      "            , cuped_metrics_2 as (\n",
      "              SELECT\n",
      "                device_id,\n",
      "                a.metric_name,\n",
      "                a.platform_type AS platform,\n",
      "                metric_result,\n",
      "                metric_covariate,\n",
      "                COALESCE(metric_result - (metric_covariate - covariate_mean) * theta, metric_result) AS cuped_result\n",
      "              FROM cuped_data_2 AS a\n",
      "                INNER JOIN cuped_values_1 AS b\n",
      "                  ON a.platform_type = b.platform_type\n",
      "                  AND a.metric_name = b.metric_name\n",
      "            )\n",
      "\n",
      "            , cuped_metrics_3 as (\n",
      "              SELECT\n",
      "                device_id,\n",
      "                a.metric_name,\n",
      "                a.platform,\n",
      "                metric_result,\n",
      "                metric_covariate,\n",
      "                COALESCE(metric_result - (metric_covariate - covariate_mean) * theta, metric_result) AS cuped_result\n",
      "              FROM cuped_data_3 AS a\n",
      "                INNER JOIN cuped_values_2 AS b\n",
      "                  ON a.platform = b.platform\n",
      "                  AND a.metric_name = b.metric_name\n",
      "            )\n",
      "\n",
      "            , cuped_results AS (\n",
      "                SELECT metric_name,\n",
      "                        'ALL' as platform,\n",
      "                        count(distinct device_id) size,\n",
      "                        avg(metric_result) result_avg,\n",
      "                        STDDEV(metric_result) result_std,\n",
      "                        avg(cuped_result) avg_cuped_result,\n",
      "                        STDDEV(cuped_result) std_cuped_result\n",
      "                FROM cuped_metrics_1\n",
      "                GROUP BY  1, 2\n",
      "\n",
      "                UNION ALL\n",
      "\n",
      "                SELECT metric_name,\n",
      "                       platform,\n",
      "                       COUNT(distinct device_id) size,\n",
      "                       AVG(metric_result) result_avg,\n",
      "                       STDDEV(metric_result) result_std,\n",
      "                       AVG(cuped_result) avg_cuped_result,\n",
      "                       STDDEV(cuped_result) std_cuped_result\n",
      "                FROM cuped_metrics_2\n",
      "                GROUP BY 1, 2\n",
      "\n",
      "                UNION ALL\n",
      "\n",
      "                SELECT metric_name,\n",
      "                       platform,\n",
      "                       COUNT(distinct device_id) size,\n",
      "                       AVG(metric_result) result_avg,\n",
      "                       STDDEV(metric_result) result_std,\n",
      "                       AVG(cuped_result) avg_cuped_result,\n",
      "                       STDDEV(cuped_result) std_cuped_result\n",
      "                FROM cuped_metrics_3\n",
      "                GROUP BY 1, 2\n",
      "            )\n",
      "\n",
      "            SELECT \n",
      "                   metric_name,\n",
      "                   platform,\n",
      "                   size AS observations,\n",
      "                   avg_cuped_result,\n",
      "                   std_cuped_result\n",
      "            FROM cuped_results        \n",
      "            \n"
     ]
    }
   ],
   "source": [
    "# output SQL for debugging purposes\n",
    "# you can manually copy and run this elsewhere\n",
    "print(FINAL_SQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tdr.query_redshift(FINAL_SQL).to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample size results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.dataresource+json": {
       "data": [
        {
         "avg_cuped_result": 5.13,
         "index": 0,
         "metric_name": "all_tvt_hours",
         "observations": 23619554,
         "platform": "ALL",
         "sample_required": 886759,
         "std_cuped_result": 12.192,
         "weeks_required": 0.2
        },
        {
         "avg_cuped_result": 1.382,
         "index": 1,
         "metric_name": "all_tvt_hours",
         "observations": 2254961,
         "platform": "IPHONE",
         "sample_required": 1438343,
         "std_cuped_result": 4.184,
         "weeks_required": 2.6
        },
        {
         "avg_cuped_result": 8.267,
         "index": 2,
         "metric_name": "all_tvt_hours",
         "observations": 98288,
         "platform": "SONY",
         "sample_required": 692157,
         "std_cuped_result": 17.358,
         "weeks_required": 28.2
        },
        {
         "avg_cuped_result": 7.706,
         "index": 3,
         "metric_name": "all_tvt_hours",
         "observations": 12980460,
         "platform": "OTT",
         "sample_required": 579627,
         "std_cuped_result": 14.808,
         "weeks_required": 0.2
        },
        {
         "avg_cuped_result": 10.08,
         "index": 4,
         "metric_name": "all_tvt_hours",
         "observations": 268144,
         "platform": "XBOXONE",
         "sample_required": 495122,
         "std_cuped_result": 17.902,
         "weeks_required": 7.4
        },
        {
         "avg_cuped_result": 8.094,
         "index": 5,
         "metric_name": "all_tvt_hours",
         "observations": 4795116,
         "platform": "ROKU",
         "sample_required": 445683,
         "std_cuped_result": 13.639,
         "weeks_required": 0.4
        },
        {
         "avg_cuped_result": 6.165,
         "index": 6,
         "metric_name": "all_tvt_hours",
         "observations": 1552611,
         "platform": "COMCAST",
         "sample_required": 409523,
         "std_cuped_result": 9.957,
         "weeks_required": 1.1
        },
        {
         "avg_cuped_result": 6.973,
         "index": 7,
         "metric_name": "all_tvt_hours",
         "observations": 165752,
         "platform": "COX",
         "sample_required": 365449,
         "std_cuped_result": 10.639,
         "weeks_required": 8.8
        },
        {
         "avg_cuped_result": 3.394,
         "index": 8,
         "metric_name": "all_tvt_hours",
         "observations": 746548,
         "platform": "VIZIO",
         "sample_required": 629327,
         "std_cuped_result": 6.797,
         "weeks_required": 3.4
        },
        {
         "avg_cuped_result": 2.332,
         "index": 9,
         "metric_name": "all_tvt_hours",
         "observations": 7295231,
         "platform": "MOBILE",
         "sample_required": 1206511,
         "std_cuped_result": 6.465,
         "weeks_required": 0.7
        },
        {
         "avg_cuped_result": 12.603,
         "index": 10,
         "metric_name": "all_tvt_hours",
         "observations": 2499657,
         "platform": "AMAZON",
         "sample_required": 502777,
         "std_cuped_result": 22.555,
         "weeks_required": 0.8
        },
        {
         "avg_cuped_result": 3.805,
         "index": 11,
         "metric_name": "all_tvt_hours",
         "observations": 1292737,
         "platform": "SAMSUNG",
         "sample_required": 954318,
         "std_cuped_result": 9.381,
         "weeks_required": 3
        },
        {
         "avg_cuped_result": 2.948,
         "index": 12,
         "metric_name": "all_tvt_hours",
         "observations": 362676,
         "platform": "IPAD",
         "sample_required": 847764,
         "std_cuped_result": 6.85,
         "weeks_required": 9.4
        },
        {
         "avg_cuped_result": 2.708,
         "index": 13,
         "metric_name": "all_tvt_hours",
         "observations": 4588485,
         "platform": "ANDROID",
         "sample_required": 1132022,
         "std_cuped_result": 7.272,
         "weeks_required": 1
        },
        {
         "avg_cuped_result": 5.981,
         "index": 14,
         "metric_name": "all_tvt_hours",
         "observations": 352021,
         "platform": "PS4",
         "sample_required": 567326,
         "std_cuped_result": 11.37,
         "weeks_required": 6.4
        }
       ],
       "schema": {
        "fields": [
         {
          "name": "index",
          "type": "integer"
         },
         {
          "name": "metric_name",
          "type": "string"
         },
         {
          "name": "platform",
          "type": "string"
         },
         {
          "name": "observations",
          "type": "integer"
         },
         {
          "name": "avg_cuped_result",
          "type": "number"
         },
         {
          "name": "std_cuped_result",
          "type": "number"
         },
         {
          "name": "sample_required",
          "type": "number"
         },
         {
          "name": "weeks_required",
          "type": "number"
         }
        ],
        "pandas_version": "0.20.0",
        "primaryKey": [
         "index"
        ]
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric_name</th>\n",
       "      <th>platform</th>\n",
       "      <th>observations</th>\n",
       "      <th>avg_cuped_result</th>\n",
       "      <th>std_cuped_result</th>\n",
       "      <th>sample_required</th>\n",
       "      <th>weeks_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all_tvt_hours</td>\n",
       "      <td>ALL</td>\n",
       "      <td>23619554</td>\n",
       "      <td>5.130</td>\n",
       "      <td>12.192</td>\n",
       "      <td>886759.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all_tvt_hours</td>\n",
       "      <td>IPHONE</td>\n",
       "      <td>2254961</td>\n",
       "      <td>1.382</td>\n",
       "      <td>4.184</td>\n",
       "      <td>1438343.0</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all_tvt_hours</td>\n",
       "      <td>SONY</td>\n",
       "      <td>98288</td>\n",
       "      <td>8.267</td>\n",
       "      <td>17.358</td>\n",
       "      <td>692157.0</td>\n",
       "      <td>28.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>all_tvt_hours</td>\n",
       "      <td>OTT</td>\n",
       "      <td>12980460</td>\n",
       "      <td>7.706</td>\n",
       "      <td>14.808</td>\n",
       "      <td>579627.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>all_tvt_hours</td>\n",
       "      <td>XBOXONE</td>\n",
       "      <td>268144</td>\n",
       "      <td>10.080</td>\n",
       "      <td>17.902</td>\n",
       "      <td>495122.0</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>all_tvt_hours</td>\n",
       "      <td>ROKU</td>\n",
       "      <td>4795116</td>\n",
       "      <td>8.094</td>\n",
       "      <td>13.639</td>\n",
       "      <td>445683.0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>all_tvt_hours</td>\n",
       "      <td>COMCAST</td>\n",
       "      <td>1552611</td>\n",
       "      <td>6.165</td>\n",
       "      <td>9.957</td>\n",
       "      <td>409523.0</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>all_tvt_hours</td>\n",
       "      <td>COX</td>\n",
       "      <td>165752</td>\n",
       "      <td>6.973</td>\n",
       "      <td>10.639</td>\n",
       "      <td>365449.0</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>all_tvt_hours</td>\n",
       "      <td>VIZIO</td>\n",
       "      <td>746548</td>\n",
       "      <td>3.394</td>\n",
       "      <td>6.797</td>\n",
       "      <td>629327.0</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>all_tvt_hours</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>7295231</td>\n",
       "      <td>2.332</td>\n",
       "      <td>6.465</td>\n",
       "      <td>1206511.0</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>all_tvt_hours</td>\n",
       "      <td>AMAZON</td>\n",
       "      <td>2499657</td>\n",
       "      <td>12.603</td>\n",
       "      <td>22.555</td>\n",
       "      <td>502777.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>all_tvt_hours</td>\n",
       "      <td>SAMSUNG</td>\n",
       "      <td>1292737</td>\n",
       "      <td>3.805</td>\n",
       "      <td>9.381</td>\n",
       "      <td>954318.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>all_tvt_hours</td>\n",
       "      <td>IPAD</td>\n",
       "      <td>362676</td>\n",
       "      <td>2.948</td>\n",
       "      <td>6.850</td>\n",
       "      <td>847764.0</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>all_tvt_hours</td>\n",
       "      <td>ANDROID</td>\n",
       "      <td>4588485</td>\n",
       "      <td>2.708</td>\n",
       "      <td>7.272</td>\n",
       "      <td>1132022.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>all_tvt_hours</td>\n",
       "      <td>PS4</td>\n",
       "      <td>352021</td>\n",
       "      <td>5.981</td>\n",
       "      <td>11.370</td>\n",
       "      <td>567326.0</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      metric_name platform  observations  avg_cuped_result  std_cuped_result  \\\n",
       "0   all_tvt_hours      ALL      23619554             5.130            12.192   \n",
       "1   all_tvt_hours   IPHONE       2254961             1.382             4.184   \n",
       "2   all_tvt_hours     SONY         98288             8.267            17.358   \n",
       "3   all_tvt_hours      OTT      12980460             7.706            14.808   \n",
       "4   all_tvt_hours  XBOXONE        268144            10.080            17.902   \n",
       "5   all_tvt_hours     ROKU       4795116             8.094            13.639   \n",
       "6   all_tvt_hours  COMCAST       1552611             6.165             9.957   \n",
       "7   all_tvt_hours      COX        165752             6.973            10.639   \n",
       "8   all_tvt_hours    VIZIO        746548             3.394             6.797   \n",
       "9   all_tvt_hours   MOBILE       7295231             2.332             6.465   \n",
       "10  all_tvt_hours   AMAZON       2499657            12.603            22.555   \n",
       "11  all_tvt_hours  SAMSUNG       1292737             3.805             9.381   \n",
       "12  all_tvt_hours     IPAD        362676             2.948             6.850   \n",
       "13  all_tvt_hours  ANDROID       4588485             2.708             7.272   \n",
       "14  all_tvt_hours      PS4        352021             5.981            11.370   \n",
       "\n",
       "    sample_required  weeks_required  \n",
       "0          886759.0             0.2  \n",
       "1         1438343.0             2.6  \n",
       "2          692157.0            28.2  \n",
       "3          579627.0             0.2  \n",
       "4          495122.0             7.4  \n",
       "5          445683.0             0.4  \n",
       "6          409523.0             1.1  \n",
       "7          365449.0             8.8  \n",
       "8          629327.0             3.4  \n",
       "9         1206511.0             0.7  \n",
       "10         502777.0             0.8  \n",
       "11         954318.0             3.0  \n",
       "12         847764.0             9.4  \n",
       "13        1132022.0             1.0  \n",
       "14         567326.0             6.4  "
      ]
     },
     "metadata": {
      "application/vnd.dataresource+json": {}
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------- Constants ---------- # \n",
    "COL_NAME_P = 'avg_cuped_result'\n",
    "STD_COL_NAME = 'std_cuped_result'\n",
    "RATIO = 1\n",
    "SAMPLING = 1  # TODO: make this dynamic between 1 and 1000 for sampled analytics\n",
    "\n",
    "CORRECTED_ALPHA = ALPHA.result / NUMBER_VARIATIONS.result\n",
    "P2_MULTIPLICATIVE_FACTOR =  1 + EFFECT_SIZE_RELATIVE.result\n",
    "    \n",
    "# ---------- Functions --------- # \n",
    "def sample_power_ttest(p1, p2, sd_diff, alpha=0.05, power=0.8, ratio=1, alternative = 'two-sided'):\n",
    "    mean_diff = abs(p2 - p1)\n",
    "    std_effect_size = mean_diff / sd_diff\n",
    "    n = tt_ind_solve_power(effect_size=std_effect_size, \n",
    "                         alpha=alpha, \n",
    "                         power=power, \n",
    "                         ratio=ratio, \n",
    "                         alternative=alternative) # Potential improvement: make this able to handle one-sided tests\n",
    "    return np.array(n).round()\n",
    "\n",
    "# ---------- Implementation ---------- #\n",
    "df['sample_required'] =  df.apply(lambda row: sample_power_ttest(\n",
    "    p1 = row[COL_NAME_P],\n",
    "    p2 = row[COL_NAME_P] * P2_MULTIPLICATIVE_FACTOR,\n",
    "    sd_diff = row[STD_COL_NAME],\n",
    "    alpha = CORRECTED_ALPHA,\n",
    "    power = POWER.result,\n",
    "    ratio = RATIO)\n",
    "                                  , axis=1)\n",
    "\n",
    "df['weeks_required'] = df['sample_required'] / (df['observations'] * 0.5 * ALLOCATION.result * SAMPLING)\n",
    "\n",
    "df['avg_cuped_result'] = df['avg_cuped_result'].round(3)\n",
    "df['std_cuped_result'] = df['std_cuped_result'].round(3)\n",
    "df['weeks_required'] = df['weeks_required'].round(1)\n",
    "\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
